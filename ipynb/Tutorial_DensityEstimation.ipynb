{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Sparse Grid Density Estimation with the Combination Technique: \n",
    "To overcome the curse of dimensionality, sparse grids are used, since full grids\n",
    "with more than three dimensions are not feasible. The basic idea of sparse grids \n",
    "is to omit some points of a full grid while retaining the subspaces that contribute \n",
    "most to the overall solution without compromising the overall accuracy. \n",
    "These sparse grids can be constructed by using the standard combination technique.\n",
    "The combination technique is a simpler method for calculating the surpluses of basis \n",
    "functions centered on grid points, rather than working directly on sparse grids based \n",
    "on the hierarchical basis, by linearly combining a certain sequence of small anisotropic\n",
    "full grids.\n",
    "\n",
    "In order to use the new grid operation, the user must pass a $\\texttt{DensityEstimation}$\n",
    "object to the $\\texttt{StandardCombi}$ constructor. It is possible to pass either a path\n",
    "to a $\\texttt{.csv}$ file to specify the data set used for density estimation, or to \n",
    "pass a $\\texttt{NumPy}$ array directly when the grid operation is created. Different\n",
    "data sets can be created with the $\\texttt{scikit-learn}$ package\n",
    "$\\texttt{sklearn.datasets}$ or with the $\\texttt{NumPy}$ package $\\texttt{random}$, \n",
    "which provides random sampling of various different distributions. \n",
    "The data is scaled to the range $(0,1)$ in the $\\texttt{initialize()}$ function \n",
    "that is called when the grid operation is performed. This has to be done because \n",
    "the implementation can only handle values between zero and one.\n",
    "\n",
    "The user can also specify a $\\lambda$ value that controls the smoothness of the \n",
    "density estimation and helps prevent overfitting when an appropriate value is \n",
    "chosen for the specific data set. In addition, the user can specify whether mass \n",
    "lumping should be used in the $R$-matrix calculation. \n",
    "Here we omit all cases where the basis functions only partially overlap, \n",
    "resulting in $R$ being a diagonal matrix. This is feasible because we use the nodal \n",
    "basis for the component grids of the combination scheme, for which the linear system \n",
    "is solved, where the $R$ matrix is already sparse \n",
    "because we have less overlapping basis functions compared to the hierarchical basis. \n",
    "This speeds up the calculation because only the diagonal values of the matrix are \n",
    "calculated and since the values on the diagonal are all the same, only one value \n",
    "on the diagonal needs to be evaluated. This accelerates the solution of the linear \n",
    "system $(R+\\lambda I) \\vec{\\alpha} = \\vec{b}$, since $R$ becomes a scalar matrix but \n",
    "also decreases the accuracy.\n",
    "\n",
    "After performing the density estimation operation by calling the \n",
    "$\\texttt{perform_operation}$ method of the $\\texttt{StandardCombi}$ object, \n",
    "the surpluses of each component grid are calculated and stored in a dictionary. \n",
    "These calculated surpluses can then be used to interpolate the density function or \n",
    "when plotting the resulting density estimation in 3D or as a contour plot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Example with the circle scikit-learn dataset with mass lumping:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sys import path\n",
    "path.append('../src/')\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from ErrorCalculator import *\n",
    "from GridOperation import *\n",
    "from StandardCombi import *\n",
    "from sklearn import datasets\n",
    "\n",
    "# dimension of the problem\n",
    "dim = 2\n",
    "\n",
    "# define size for the generated data sets\n",
    "size = 500\n",
    "\n",
    "# define the domain boundaries\n",
    "a = np.zeros(dim)\n",
    "b = np.ones(dim)\n",
    "\n",
    "# define the data\n",
    "data = datasets.make_circles(size, noise = 0.05)\n",
    "\n",
    "# initialize the grid operation\n",
    "operation = DensityEstimation(data, dim, masslumping=True, lambd= 0.0)\n",
    "\n",
    "# initialize the StandardCombi with the DE\n",
    "combiObject = StandardCombi(a, b, operation=operation)\n",
    "\n",
    "# define the min and max level of the combi grid\n",
    "minimum_level = 1\n",
    "maximum_level = 5\n",
    "\n",
    "# perform the density estimation operation, has to be done before the printing and plotting\n",
    "combiObject.perform_operation(minimum_level, maximum_level)\n",
    "print(\"Combination Scheme:\")\n",
    "# when you pass the operation the function also plots the contour plot of each component grid\n",
    "combiObject.print_resulting_combi_scheme(operation=operation)\n",
    "print(\"Sparse Grid:\")\n",
    "combiObject.print_resulting_sparsegrid(markersize=20)\n",
    "print(\"Plot of dataset:\")\n",
    "operation.plot_dataset()\n",
    "print(\"Plot of density estimation:\")\n",
    "# when contour = True, the contour plot is shown next to the 3D plot\n",
    "combiObject.plot(contour=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Example with numpy random sampling (multivariate Gaussian distribution):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "operation.masslumping = False\n",
    "\n",
    "# multivariate normal distribution\n",
    "mean = np.array([0.0] * dim)\n",
    "sigma = np.array([0.25]*dim)\n",
    "cov = np.diag(sigma**2)\n",
    "data = np.random.multivariate_normal(mean, cov, size)\n",
    "operation.data = data\n",
    "\n",
    "combiObject.perform_operation(minimum_level, maximum_level)\n",
    "print(\"Plot of dataset:\")\n",
    "operation.plot_dataset()\n",
    "print(\"Plot of density estimation\")\n",
    "combiObject.plot(contour=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Example with the old faithful geyser dataset with $\\lambda = 0.001$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "oldFaithfulDataset = \"../SGDE/Datasets/faithful.csv\"\n",
    "\n",
    "operation.data = oldFaithfulDataset\n",
    "combiObject.perform_operation(minimum_level, maximum_level)\n",
    "print(\"Plot of dataset:\")\n",
    "operation.plot_dataset()\n",
    "print(\"Plot of density estimation\")\n",
    "combiObject.plot(contour=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
